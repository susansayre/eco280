---
date: "2020-01-28T00:36:14+09:00"
title: HW 4 - Data wrangling
output: 
  md_document:
    preserve_yaml: true
    pandoc_args: ["--wrap=preserve"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

```

# Submission details

-   Commit and **push** working code to your github repo by 9am EST on **Thurs 10/8**
-   Note atypical due date due to Mountain Day adjustments

# Learning objectives

This homework is designed to give you practice working with five basic data wrangling tasks using data from the New York Times on coronavirus cases. There are many tutorials online describing the “five main verbs” of `dplyr` (which is part of the `tidyverse`) that show how to accomplish these tasks in R using dplyr/tidyverse. This homework asks you to complete the tasks in both R and Stata. The five basic operations and associated commands are:

----------------------------   ------------------------   -------------------------
 **Data task**                 **dplyr commands**         **Stata commands**           
 choosing/renaming variables   select, rename, relocate   keep, drop, rename, order 
 sorting data                  arrange                    sort                      
 subsetting data               filter                     keep if, drop if          
 creating/modifying variables  mutate                     gen, replace, egen        
 computing summary statistics  summarize                  summary, collapse         
----------------------------   ------------------------   -------------------------

Unlike our previous homework assignments, for this homework assignment, I will provide an example of what I want the output to look like and will provide some suggestions on how to construct the code to accomplish this, but will not provide the specific code. Your job is to use the examples I demonstrated in class and those from the documentation provided to generate code that accomplishes its goal.

Full credit for the homework assignment requires:
- A knitted html file produced from the .Rmd file that contains output matching the examples
- The .Rmd file that produces the html file 
- A Stata do file that produces a dataset matching the basic table described below
- The Stata log file from running the do file that contains no errors

For this assignment, begin with R and conduct your analysis in an RMarkdown document. It should contain several sections with headers to identify them.

## Data source

This section should include a short statement of where you located the data. You will be downloading the data from the [New York Times coronavirus git repo](https://github.com/nytimes/covid-19-data). You should read through the description of the data and provide a very brief description of the data and any important things you notice from the description here. (This should not be long. 1-4 sentences is sufficient.)

The specific file link is [https://raw.githubusercontent.com/nytimes/covid-19-data/master/live/us-counties.csv](https://raw.githubusercontent.com/nytimes/covid-19-data/master/live/us-counties.csv). Download the data to your computer, store it as a .csv file in a folder called data and create a markdown file (*not an RMarkdown file*) called README.md inside the data folder that describes where you got the data.

## Basic data table

Your first task is to construct a table of the total number of new cases each day in each of the six New England states (Connecticut, Massachusetts, Rhode Island, Maine, Vermont, and New Hampshire) starting on March 15, 2020 and continuing through the day you downloaded the data. Note that the New York Times data archive does include data by state, but your job is to start with the *county* level data to construct the state measures.

The first rows of your table should look like this:
```{r load data from git, echo = F, message = F}
county_data <- read_csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv") %>% 
  group_by(county, state) %>% 
  mutate(new_cases = cases - lag(cases)) %>% 
  select(date, county, state, new_cases, total_cases = cases)

ne_data <- county_data %>% 
  group_by(date, state) %>% 
  summarize(new_cases = sum(new_cases, na.rm = T), cases_to_date = sum(total_cases, na.rm = T)) %>% 
  filter(date >= as.Date("2020-03-15")) %>% 
  filter(state %in% c("Connecticut", "Massachusetts", "Rhode Island", "Maine", "New Hampshire", "Vermont"))

head(ne_data)

```

Since the data only reports total cases to date, you will need to construct the new cases each day by using dplyr's `lag()` function. To use this function, you'll also want to sort the data by geographic region and by date and then group by geographic region. Then `lag(cases)` will give you the value of `cases` in a particular jurisdiction on the previous day.

To get from county level data to state level data, you'll need to follow the steps from class to compute totals.

You should also make sure that only the data for New England is included and that the variables are in the order shown in the example table and have the same names. Use the head() function to print the first few rows of the table in your output.

Once you've generated the table in your Rmd, construct a do file that creates the same table in Stata. You do **not** need to complete the remaining tasks in Stata. Push your do file and a log file to git. To generate the new case variable in Stata, adapt the code from [this manual page](https://www.stata.com/support/faqs/data-management/creating-lagged-variables/).

## Investigate the data

Find that maximum and minimum number of new cases reported on an individual day in each state. (You do **not** need to keep track of *which* day this occurred on). Have your code print the answer in a table by state using either the head() or the print() function. After the table describe what you notice in a text section of the .Rmd file. Your table should look like this one, but will contain data for the New England states instead of these ones.

```{r sample max/min, echo = F, message = F}
example_data <- county_data %>% 
  group_by(date, state) %>% 
  filter(state %in% c("New York", "Pennsylvania", "Maryland", "Virginia")) %>% 
  summarize(new_cases = sum(new_cases, na.rm = T), cases_to_date = sum(total_cases, na.rm = T)) 

max_min <- example_data %>% 
  group_by(state) %>% 
  summarize(max_daily_new_cases = max(new_cases), min_daily_new_cases = min(new_cases))

head(max_min)
```

Using the `wday()` function from the lubridate package, find the day of the week for each day and compute the average number of new cases for each day of the week. Again, use head() or print() to share the results and describe any pattern you notice.

## Generate a plot
Generate a series of side-by-side plots of new cases by day in each state by day that looks like the example below. When you first plot the data, at least one state will look very different. You'll need to use the facet_wrap() layer to create the small multiples. Try typing ?facet_wrap in the console to figure out how to set the axes to vary across states so that you can see the lines for all the states. Write a brief description of the changes you have to make to get the graph to look like the example and use the `caption = "caption text"` argument to the `labs()` layer of your ggplot call to add a note to the chart explaining the change you made. (Hint: one of the earlier tasks may help you determine what to change.)

```{r new cases plot, echo = F, message = F}
ne_data %>% filter(new_cases>0) %>% 
ggplot(aes(date, new_cases)) + 
  geom_line() + 
  geom_smooth(method = "loess") + 
  facet_wrap(vars(state), scales = "free") +
  labs(title = "Daily new coronavirus cases in New England", 
       caption = "Add a note describing the data adjustment that makes the plot look like this.") +
  ylab("New cases") +
  xlab("Date") 
```
